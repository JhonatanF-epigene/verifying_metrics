{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions from the files on the bronze zone\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three steps in this notebook to achieving our objective:\n",
    "- open the zarr from Azure, and using it inside the notebook\n",
    "- making the predictions (for different thresholds) with the datasets from the bronze zone\n",
    "- saving the file only with the indexes and the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhonatan/Desktop/Verifying_metrics/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/jhonatan/Desktop/Verifying_metrics/.venv/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from data_integration_utils.azure_blob_manager.omic_blob_manager import OmicBronzeBSM, OmicGoldBSM\n",
    "import zarr\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import (\n",
    "    execute_cancer_finder,\n",
    "    execute_sctab,\n",
    "    unified_models_output\n",
    ")\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to setup the doppler, I used a file token_doppler with my token to use it\n",
    "\n",
    "from token_doppler import TOKEN\n",
    "from dopplersdk import DopplerSDK\n",
    "import os\n",
    "\n",
    "doppler = DopplerSDK()\n",
    "doppler.set_access_token(TOKEN)\n",
    "results = doppler.projects.list()\n",
    "\n",
    "project = \"data-integration-omic\"\n",
    "config =  \"dev\"\n",
    "secrets = doppler.secrets.list(config, project)\n",
    "\n",
    "def charge_variable_doppler(variable):\n",
    "    os.environ[variable] = secrets.secrets[variable]['computed']\n",
    "\n",
    "charge_variable_doppler(\"AZURE_DATASETS_ACCOUNT_URL\")\n",
    "charge_variable_doppler(\"SLACK_CONF\")\n",
    "charge_variable_doppler('AZURE_DATASETS_ACCOUNT_URL')\n",
    "charge_variable_doppler('DATA_MLFLOW_SOURCE_CONTAINER_NAME')\n",
    "charge_variable_doppler('DATA_MLFLOW_SOURCE_ACCOUNT_URL')\n",
    "\n",
    "## Is not the dataintdevs\n",
    "os.environ[\"AZURE_DATASETS_ACCOUNT_URL\"] = 'https://dataintepigene.blob.core.windows.net/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sctab = [\n",
    "    \"GSE132257\",\n",
    "    \"GSE132465\",\n",
    "    \"GSE178341\",\n",
    "    \"GSE159929\",\n",
    "    \"GSE200996\",\n",
    "    \"GSE139555\",\n",
    "    \"GSE116256\",\n",
    "    \"GSE234129\",\n",
    "    \"GSE159115\",\n",
    "    \"GSE180298\",\n",
    "    \"BerlinSC\",\n",
    "    \"SCP1288\",\n",
    "    \"Tabula_sapiens_Bladder\",\n",
    "    \"Tabula_sapiens_Blood\",\n",
    "    \"Tabula_sapiens_Bone_Marrow\",\n",
    "    \"Tabula_sapiens_Eye\",\n",
    "    \"Tabula_sapiens_Fat\",\n",
    "    \"Tabula_sapiens_Heart\",\n",
    "    \"Tabula_sapiens_Kidney\",\n",
    "    \"Tabula_sapiens_Liver\",\n",
    "    \"Tabula_sapiens_Large_Intestine\",\n",
    "    \"Tabula_sapiens_Lung\",\n",
    "    \"Tabula_sapiens_Lymph_Node\",\n",
    "    \"Tabula_sapiens_Mammary\",\n",
    "    \"Tabula_sapiens_Muscle\",\n",
    "    \"Tabula_sapiens_Pancreas\",\n",
    "    \"Tabula_sapiens_Prostate\",\n",
    "    \"Tabula_sapiens_Skin\",\n",
    "    \"Tabula_sapiens_Small_Intestine\",\n",
    "    \"Tabula_sapiens_Spleen\",\n",
    "    \"Tabula_sapiens_Thymus\",\n",
    "    \"Tabula_sapiens_Tongue\",\n",
    "    \"Tabula_sapiens_Trachea\",\n",
    "    \"Tabula_sapiens_Uterus\",\n",
    "    \"Tabula_sapiens_Vasculature\"\n",
    "]\n",
    "\n",
    "slack_conf = json.loads(os.environ[\"SLACK_CONF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adata_bronze(dataset):\n",
    "    bronze_bsm = OmicBronzeBSM()\n",
    "    bronze_store = zarr.open_group(zarr.ABSStore(client=bronze_bsm.container_client, prefix=f\"bronze/scrnaseq/{dataset}_raw_data.zarr\"))\n",
    "    adata = anndata.read_zarr(bronze_store)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = datasets_sctab[0]\n",
    "#adata = load_adata_bronze(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_id</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>Status</th>\n",
       "      <th>Sample</th>\n",
       "      <th>paper_cell_type_1</th>\n",
       "      <th>dataset</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>epigene_cell_type</th>\n",
       "      <th>epigene_cell_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM3855020_AAACCTGAGATCGGGT</th>\n",
       "      <td>SMC13</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>SMC13N-A1-F</td>\n",
       "      <td>T cells</td>\n",
       "      <td>GSE132257</td>\n",
       "      <td>GSM3855020</td>\n",
       "      <td>T cell</td>\n",
       "      <td>T cell, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM3855020_AAACCTGAGGATTCGG</th>\n",
       "      <td>SMC13</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>SMC13N-A1-F</td>\n",
       "      <td>T cells</td>\n",
       "      <td>GSE132257</td>\n",
       "      <td>GSM3855020</td>\n",
       "      <td>T cell</td>\n",
       "      <td>T cell, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM3855020_AAACCTGGTACTCAAC</th>\n",
       "      <td>SMC13</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>SMC13N-A1-F</td>\n",
       "      <td>T cells</td>\n",
       "      <td>GSE132257</td>\n",
       "      <td>GSM3855020</td>\n",
       "      <td>T cell</td>\n",
       "      <td>T cell, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM3855020_AAACGGGAGCTTTGGT</th>\n",
       "      <td>SMC13</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>SMC13N-A1-F</td>\n",
       "      <td>B cells</td>\n",
       "      <td>GSE132257</td>\n",
       "      <td>GSM3855020</td>\n",
       "      <td>B cell</td>\n",
       "      <td>B cell, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM3855020_AAACGGGCATCCAACA</th>\n",
       "      <td>SMC13</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>SMC13N-A1-F</td>\n",
       "      <td>B cells</td>\n",
       "      <td>GSE132257</td>\n",
       "      <td>GSM3855020</td>\n",
       "      <td>B cell</td>\n",
       "      <td>B cell, NOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            donor_id sample_type  Status       Sample  \\\n",
       "GSM3855020_AAACCTGAGATCGGGT    SMC13      Normal  Frozen  SMC13N-A1-F   \n",
       "GSM3855020_AAACCTGAGGATTCGG    SMC13      Normal  Frozen  SMC13N-A1-F   \n",
       "GSM3855020_AAACCTGGTACTCAAC    SMC13      Normal  Frozen  SMC13N-A1-F   \n",
       "GSM3855020_AAACGGGAGCTTTGGT    SMC13      Normal  Frozen  SMC13N-A1-F   \n",
       "GSM3855020_AAACGGGCATCCAACA    SMC13      Normal  Frozen  SMC13N-A1-F   \n",
       "\n",
       "                            paper_cell_type_1    dataset   sample_id  \\\n",
       "GSM3855020_AAACCTGAGATCGGGT           T cells  GSE132257  GSM3855020   \n",
       "GSM3855020_AAACCTGAGGATTCGG           T cells  GSE132257  GSM3855020   \n",
       "GSM3855020_AAACCTGGTACTCAAC           T cells  GSE132257  GSM3855020   \n",
       "GSM3855020_AAACGGGAGCTTTGGT           B cells  GSE132257  GSM3855020   \n",
       "GSM3855020_AAACGGGCATCCAACA           B cells  GSE132257  GSM3855020   \n",
       "\n",
       "                            epigene_cell_type epigene_cell_subtype  \n",
       "GSM3855020_AAACCTGAGATCGGGT            T cell          T cell, NOS  \n",
       "GSM3855020_AAACCTGAGGATTCGG            T cell          T cell, NOS  \n",
       "GSM3855020_AAACCTGGTACTCAAC            T cell          T cell, NOS  \n",
       "GSM3855020_AAACGGGAGCTTTGGT            B cell          B cell, NOS  \n",
       "GSM3855020_AAACGGGCATCCAACA            B cell          B cell, NOS  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RP11-34P13.3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM138A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP11-34P13.7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP11-34P13.8</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [RP11-34P13.3, FAM138A, OR4F5, RP11-34P13.7, RP11-34P13.8]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(adata, dataset, sctab, cancerfinder, seed = None ):\n",
    "    \n",
    "    list_intersect_cf = None\n",
    "    list_intersect_sctab = None\n",
    "\n",
    "    if seed is None:\n",
    "        if cancerfinder:\n",
    "            version = 'CF'\n",
    "            adata, intersec_cf, list_intersect_cf = execute_cancer_finder(adata,slack_conf)\n",
    "            intersec_cf = round(intersec_cf, 2)\n",
    "            path = f\"./metrics_annotation_models/predictions/{dataset}_{version}_{intersec_cf}.csv\"\n",
    "        if sctab:\n",
    "            version = 'scTab'\n",
    "            adata, intersec_sc, list_intersect_sctab = execute_sctab(adata)\n",
    "            intersec_sc = round(intersec_sc, 2)\n",
    "            path = f\"./metrics_annotation_models/predictions/{dataset}_{version}_{intersec_sc}.csv\"\n",
    "        if sctab or cancerfinder:\n",
    "            adata = unified_models_output(adata)\n",
    "        if sctab and cancerfinder:\n",
    "            version = 'complete'\n",
    "            path = f\"./metrics_annotation_models/predictions/{dataset}_{version}_{intersec_sc}_{intersec_cf}.csv\"\n",
    "    else:\n",
    "        path = path.split(\".csv\")[0] + f'_{str(seed)}' + path.split(\".csv\")[1]\n",
    "    return adata, path, list_intersect_cf, list_intersect_sctab\n",
    "\n",
    "def save_reduced_observations(adata, path, sctab = True, cancerfinder = True):\n",
    "    columns = [\"epigene_cell_type\", \n",
    "            \"epigene_cell_subtype\", \n",
    "            \"metapipeline_automatic_cell_type\"\n",
    "            ]\n",
    "    if cancerfinder:\n",
    "        columns.append(\"prediction_CancerFinder\")\n",
    "    if sctab:\n",
    "        columns.append(\"predicted_mapped_scTab\")\n",
    "    adata.obs[columns].to_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "dataset = datasets_sctab[0]\n",
    "\n",
    "adata = load_adata_bronze(dataset)\n",
    "adata_final, path, _, _ = predict_dataset(adata, dataset, cancerfinder= True, sctab= True)\n",
    "save_reduced_observations(adata, path, sctab = True, cancerfinder= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now the way to follow as a pipeline is to use the functions in the following way:\n",
    "### load_adata_bronze -> predict_and_save_dataset\n",
    "\n",
    "### now the idea is to use the load_adata_bronze to get the adata, after filter using \n",
    "### another function specifying the version with the number of the seed, and after \n",
    "### that make the predictions ans save passing the function predict_and_save_dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap for genes dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33694"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes_sctab = 19331 \n",
    "n_genes_cancerfinder = 0\n",
    "\n",
    "# def dropout_genes(adata, drop_fraction = 0.1, random_state = 42):\n",
    "#     \"\"\"\n",
    "#     Function to make a gene dropout on the dataset oy choose.\n",
    "\n",
    "#     adata: \n",
    "#     drop_fraction: fraction of the dataset you choose to drop.\n",
    "#     random_state: chose the seed for the random method to assure reproducibility\n",
    "#     \"\"\"\n",
    "#     n_genes = adata.n_vars\n",
    "#     n_drop = int(n_genes*drop_fraction)\n",
    "\n",
    "#     np.random.seed(random_state)\n",
    "#     drop_indices = np.random.choice(n_genes, n_drop, replace= False)\n",
    "\n",
    "#     keep_mask = np.ones(n_genes, dtype = bool)\n",
    "#     keep_mask[drop_indices] = False\n",
    "\n",
    "#     adata_dropped = adata[:, keep_mask].copy()\n",
    "\n",
    "#     return adata_dropped\n",
    "\n",
    "\n",
    "def dropout_genes(adata, gene_list, n_genes_model ,drop_fraction=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Filters the AnnData object to the provided list of genes, then drops a fraction of them at random.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    adata : AnnData\n",
    "        The input annotated data matrix.\n",
    "    gene_list : list of str\n",
    "        The list of genes (variables) to retain before dropout.\n",
    "    n_genes_model: int\n",
    "        Quantity of genes for the models we are using in the moment.\n",
    "    drop_fraction : float, optional (default=0.1)\n",
    "        Fraction of the filtered genes to randomly drop.\n",
    "    random_state : int, optional (default=42)\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    AnnData\n",
    "        A new AnnData object with the selected genes filtered and a subset dropped.\n",
    "    \"\"\"\n",
    "    # Filter adata for selected genes\n",
    "    adata_filtered = adata[:, gene_list].copy()\n",
    "    \n",
    "    # Dropout calculation\n",
    "    n_genes = n_genes_model\n",
    "    n_drop = int(n_genes * drop_fraction)\n",
    "    if n_drop == 0:\n",
    "        return adata_filtered  # Return unchanged if nothing is to be dropped\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    drop_indices = np.random.choice(n_genes, n_drop, replace=False)\n",
    "\n",
    "    keep_mask = np.ones(n_genes, dtype=bool)\n",
    "    keep_mask[drop_indices] = False\n",
    "\n",
    "    adata_dropped = adata_filtered[:, keep_mask].copy()\n",
    "    \n",
    "    return adata_dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions made on the different datasets from the list for scTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sctab = [\n",
    "    \"GSE132257\",\n",
    "    \"GSE132465\",\n",
    "    \"GSE178341\",\n",
    "    \"GSE159929\",\n",
    "    \"GSE200996\",\n",
    "    \"GSE139555\",\n",
    "    \"GSE116256\",\n",
    "    \"GSE234129\",\n",
    "    \"GSE159115\",\n",
    "    \"GSE180298\",\n",
    "    \"BerlinSC\",\n",
    "    \"SCP1288\",\n",
    "    \"Tabula_sapiens_Bladder\",\n",
    "    \"Tabula_sapiens_Blood\",\n",
    "    \"Tabula_sapiens_Bone_Marrow\",\n",
    "    \"Tabula_sapiens_Eye\",\n",
    "    \"Tabula_sapiens_Fat\",\n",
    "    \"Tabula_sapiens_Heart\",\n",
    "    \"Tabula_sapiens_Kidney\",\n",
    "    \"Tabula_sapiens_Liver\",\n",
    "    \"Tabula_sapiens_Large_Intestine\",\n",
    "    \"Tabula_sapiens_Lung\",\n",
    "    \"Tabula_sapiens_Lymph_Node\",\n",
    "    \"Tabula_sapiens_Mammary\",\n",
    "    \"Tabula_sapiens_Muscle\",\n",
    "    \"Tabula_sapiens_Pancreas\",\n",
    "    \"Tabula_sapiens_Prostate\",\n",
    "    \"Tabula_sapiens_Skin\",\n",
    "    \"Tabula_sapiens_Small_Intestine\",\n",
    "    \"Tabula_sapiens_Spleen\",\n",
    "    \"Tabula_sapiens_Thymus\",\n",
    "    \"Tabula_sapiens_Tongue\",\n",
    "    \"Tabula_sapiens_Trachea\",\n",
    "    \"Tabula_sapiens_Uterus\",\n",
    "    \"Tabula_sapiens_Vasculature\"\n",
    "]\n",
    "\n",
    "datasets_cancerfinder = [\n",
    "    \"BerlinSC\", \n",
    "    \"GSE132465\", \n",
    "    \"SCP1288\", \n",
    "    \"GSE159115\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/7kq86smn27b7j7l6xzvtjlm00000gn/T/ipykernel_71111/3344461464.py:6: FutureWarning: The ABSStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  adata = load_adata_bronze(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes in intersection: 17499\n",
      "Adding 6792 missing genes with zero values.\n",
      "Matrix shape: (24291, 18409)\n",
      "AnnData object with n_obs × n_vars = 24291 × 18409\n",
      "/n\n",
      "AnnData object with n_obs × n_vars = 24291 × 18409\n",
      "begin 0\n",
      "begin 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhonatan/Desktop/Verifying_metrics/mlflow-models/packages/SequencingCancerFinder/CancerFinder.py:224: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  predict_df['predict'][predict_df['predict'] > self.args.threshold] = 1\n",
      "/Users/jhonatan/Desktop/Verifying_metrics/mlflow-models/packages/SequencingCancerFinder/CancerFinder.py:225: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  predict_df['predict'][predict_df['predict'] != 1 ] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature_id feature_name\n",
      "0      ENSG00000186092        OR4F5\n",
      "1      ENSG00000284733       OR4F29\n",
      "2      ENSG00000284662       OR4F16\n",
      "3      ENSG00000187634       SAMD11\n",
      "4      ENSG00000188976        NOC2L\n",
      "...                ...          ...\n",
      "19326  ENSG00000288702       UGT1A3\n",
      "19327  ENSG00000288705       UGT1A5\n",
      "19328  ENSG00000182484       WASH6P\n",
      "19329  ENSG00000288622   PDCD6-AHRR\n",
      "19330  ENSG00000285815  GET1-SH3BGR\n",
      "\n",
      "[19331 rows x 2 columns]\n",
      "##################################################################\n",
      "The quantity of genes in this dataset is 33694\n",
      "The quantity of genes in the model is 19331\n",
      "The percentage of intesection for sctab is 0.9458382908282034\n",
      "##################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.12s/it]\n",
      "/Users/jhonatan/Desktop/Verifying_metrics/utils.py:1054: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata_combined.obs[columns_scTab] = df_processed[columns_processed]\n",
      "/var/folders/x_/7kq86smn27b7j7l6xzvtjlm00000gn/T/ipykernel_71111/3344461464.py:6: FutureWarning: The ABSStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  adata = load_adata_bronze(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes in intersection: 17499\n",
      "Adding 6792 missing genes with zero values.\n",
      "Matrix shape: (24291, 63689)\n",
      "AnnData object with n_obs × n_vars = 24291 × 63689\n",
      "/n\n",
      "AnnData object with n_obs × n_vars = 24291 × 63689\n",
      "begin 0\n",
      "begin 1\n",
      "begin 2\n",
      "begin 3\n",
      "begin 4\n",
      "begin 5\n",
      "begin 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhonatan/Desktop/Verifying_metrics/mlflow-models/packages/SequencingCancerFinder/CancerFinder.py:224: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  predict_df['predict'][predict_df['predict'] > self.args.threshold] = 1\n",
      "/Users/jhonatan/Desktop/Verifying_metrics/mlflow-models/packages/SequencingCancerFinder/CancerFinder.py:225: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  predict_df['predict'][predict_df['predict'] != 1 ] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature_id feature_name\n",
      "0      ENSG00000186092        OR4F5\n",
      "1      ENSG00000284733       OR4F29\n",
      "2      ENSG00000284662       OR4F16\n",
      "3      ENSG00000187634       SAMD11\n",
      "4      ENSG00000188976        NOC2L\n",
      "...                ...          ...\n",
      "19326  ENSG00000288702       UGT1A3\n",
      "19327  ENSG00000288705       UGT1A5\n",
      "19328  ENSG00000182484       WASH6P\n",
      "19329  ENSG00000288622   PDCD6-AHRR\n",
      "19330  ENSG00000285815  GET1-SH3BGR\n",
      "\n",
      "[19331 rows x 2 columns]\n",
      "##################################################################\n",
      "The quantity of genes in this dataset is 33694\n",
      "The quantity of genes in the model is 19331\n",
      "The percentage of intesection for sctab is 0.9458382908282034\n",
      "##################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:32<00:00,  1.01s/it]\n",
      "/Users/jhonatan/Desktop/Verifying_metrics/utils.py:1054: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata_combined.obs[columns_scTab] = df_processed[columns_processed]\n",
      "/var/folders/x_/7kq86smn27b7j7l6xzvtjlm00000gn/T/ipykernel_71111/3344461464.py:6: FutureWarning: The ABSStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  adata = load_adata_bronze(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes in intersection: 16833\n",
      "Adding 7458 missing genes with zero values.\n",
      "Matrix shape: (24291, 370115)\n",
      "AnnData object with n_obs × n_vars = 24291 × 370115\n",
      "/n\n",
      "AnnData object with n_obs × n_vars = 24291 × 370115\n",
      "begin 0\n",
      "begin 1\n",
      "begin 2\n",
      "begin 3\n",
      "begin 4\n",
      "begin 5\n",
      "begin 6\n",
      "begin 7\n",
      "begin 8\n",
      "begin 9\n",
      "begin 10\n",
      "begin 11\n",
      "begin 12\n",
      "begin 13\n",
      "begin 14\n",
      "begin 15\n",
      "begin 16\n",
      "begin 17\n",
      "begin 18\n",
      "begin 19\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "slack_conf = json.loads(os.environ[\"SLACK_CONF\"])\n",
    "\n",
    "non_successful_datasets = []\n",
    "cf = True\n",
    "sct = True\n",
    "for dataset in datasets_sctab:\n",
    "    try:\n",
    "        adata = load_adata_bronze(dataset)\n",
    "        adata, path, _, _ = predict_dataset(adata, dataset, cancerfinder= cf, sctab= sct)\n",
    "        save_reduced_observations(adata, path, sctab = sct, cancerfinder= cf)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {dataset}: {e}\")\n",
    "        non_successful_datasets.append(dataset)\n",
    "        continue  # skip to the next dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the predictions for different quantities of intersections:\n",
    "\n",
    "- Have to verify which are the number of intersection for the datasets because I can calculate only for a smaller number for them\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(different predictions)",
   "language": "python",
   "name": "annotation-predictions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
